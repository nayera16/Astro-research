{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763e51fb",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src='logo.png' alt=\"logo\" class=\"bg-primary\" align=\"right\" style=\"width: 150px; height: 150px;\"/>\n",
    "</figure>\n",
    "\n",
    "<a id='top'></a>\n",
    "# NIRSpec IFU Pipeline Processing for point sources: ERO 2732 - NGC 7319 AGN\n",
    "<hr style=\"border:3px solid black\"  width=80% align=\"left\">\n",
    "\n",
    "\n",
    "## About this Notebook <a id='about'></a>\n",
    "<hr style=\"border:1px solid gray\" width=80% align=\"left\">\n",
    "\n",
    "**Authors**: Peter Zeidler (zeidler@stsci.edu) based on the work by Kayli Glidic (kglidic@stsci.edu), Maria Pena-Guerrero (pena@stsci.edu), Leonardo Ubeda (lubeda@stsci.edu)\n",
    "\n",
    "**Update On**: 2023-11-28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8462867-73ac-4a69-8198-7ddac26b638d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Import Library](#imports)\n",
    "* [3. Convenience Functions](#func)\n",
    "* [4. Directory Set-Up](#dir_setup)\n",
    "* [5. Download the data](#data)\n",
    "* [6. Products Found In MAST](#mast_products)\n",
    "* [7. Re-processing the Data](#reprocessing)\n",
    "    * [7.1 Stage 1 Rerun & Products](#level1_rerun)\n",
    "    * [7.2 Stage 2 Rerun & Products](#level2_rerun)\n",
    "    * [7.3 Stage 3 Rerun & Products](#level3_rerun)\n",
    "        * [7.3.1 New Outlier Detection Algorithm](#outlier_detection_new)\n",
    "* [8. Extract 1-D Step: Modified Reference File](#extract_1d)\n",
    "* [Conclusion](#conclusion)\n",
    "\n",
    "## 1. Introduction <a id='intro'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "End-to-end calibration of JWST data is divided into 3 main stages of processing. This notebook explores how to run the JWST calibration pipeline stages 1-3 for NIRSpec IFU spectroscopic data.\n",
    "   <figure>\n",
    "       <img src='./nirspec_ifu_point_source/NGC_7319_AGN.png' title=\"Figure 1: NGC 7319 AGN\" alt=\"NGC 7319 AGN\" class=\"bg-primary\" align=\"right\" style=\"width: 400px; height: 350px;\"/>\n",
    "   </figure>\n",
    "\n",
    ">* **`STAGE 1`** ([calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)): consists of detector-level corrections, performed on a group-by-group basis, followed by ramp fitting.\n",
    "    * **Input**: Raw exposure (`uncal.fits`) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n",
    "    * **Output**: Corrected countrate (slope) image (`rate.fits`) \n",
    ">* **`STAGE 2`** ([calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html#calwebb-spec2)): consists of additional instrument-level and observing mode corrections and calibrations.\n",
    "    * **Input**: A single corrected countrate (slope) image (`rate.fits`) or an ASN file listing multiple inputs.\n",
    "    * **Output**: A fully calibrated unrectified exposure (`cal.fits`). For NIRSpec IFU data, the `cube_build` step returns a 3-D IFU spectroscopic cube (`s3d.fits`). The `extract_1d` step  returns 1-D extracted spectral data products (`x1d.fits`)\n",
    ">* **`STAGE 3`** ([calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3)): consists of additional corrections (e.g. `outlier_detection`) and routines for combining calibrated data from multiple exposures (e.g. dither/nod pattern) into a single combined 2-D or 3-D spectral product and a combined 1-D spectrum. \n",
    "    * **Input**: An ASN file that lists multiple calibrated exposures (`cal.fits`).\n",
    "    * **Output**: For NIRSpec IFU data, a resampled and combined 3-D IFU cube (`s3d.fits`) and a 1-D extracted spectrum (`x1d.fits`)\n",
    "\n",
    "Here, we will focus on the mechanics of processing \"real\" example data (NGC 7319 AGN) from Proposal ID 2732, including how to use associations for multi-exposure combination and how to interact and work with data models for each product. Our objective is to examine the automated products found in MAST and compare them to products generated with the most up-to-date version of the JWST calibration pipeline.\n",
    "\n",
    "Most processing runs shown here use the default reference files from the Calibration Reference Data System (CRDS). Please note that pipeline software development is a continuous process, so results in some cases may be slightly different if using a subsequent version. There are also a few known issues with some of the pipeline steps in this build that we expect to be fixed in the near future. Until then, at various steps, we provide users with the current processing recommendations when running the pipeline manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee7ed7",
   "metadata": {},
   "source": [
    "## 2. Import Library <a id='imports'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5b543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CRDS_CONTEXT=jwst_1146.pmap\n",
      "===============================================================================\n",
      "These are the installed pipeline and current operational CRDS context versions:\n",
      " \n",
      "JWST Calibration Pipeline Version=1.12.5\n",
      "Current Operational CRDS Context = jwst_1166.pmap\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "\n",
    "#--------------------------------------JWST Calibration Pipeline Imports-------------------------------------------\n",
    "\n",
    "import jwst\n",
    "import crds\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline   #calwebb_detector1\n",
    "from jwst.pipeline import Spec2Pipeline       #calwebb_spec2\n",
    "from jwst.pipeline import Spec3Pipeline       #calwebb_spec3\n",
    "from jwst.extract_1d import Extract1dStep     #Extract1D Individual Step\n",
    "\n",
    "%env CRDS_CONTEXT  jwst_1146.pmap\n",
    "\n",
    "print(\"===============================================================================\")\n",
    "print(\"These are the installed pipeline and current operational CRDS context versions:\")\n",
    "print(\" \")\n",
    "print(\"JWST Calibration Pipeline Version={}\".format(jwst.__version__))\n",
    "print(\"Current Operational CRDS Context = {}\".format(crds.get_default_context()))\n",
    "print(\"===============================================================================\")\n",
    "\n",
    "#----------------------------------------------General Imports-----------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Set to 'default' to turn warnings back on\n",
    "\n",
    "#--------------------------------------------File Operation Imports------------------------------------------------\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import asdf\n",
    "import json\n",
    "import shutil\n",
    "from IPython.display import JSON\n",
    "\n",
    "#--------------------------------------------Astropy/Astroquery Imports--------------------------------------------\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch, LinearStretch, AsinhStretch, SqrtStretch\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import astroquery\n",
    "from astroquery.mast import Mast\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "#------------------------------------------------Plotting Imports--------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.gridspec as grd\n",
    "from matplotlib import cm\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "#%matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17178e7",
   "metadata": {},
   "source": [
    "## 3. Convenience Functions <a id='func'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb4f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xsize=15, ysize=15, title=None, zoom_in=None, aspect=1, scale='log', units='DN/s', cmap='jet'):\n",
    "    \"\"\"\n",
    "    Function to generate a 2-D, log-scaled image of the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2-D image to be displayed\n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "    xsize, ysize: int\n",
    "        Figure Size\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    zoom_in: list \n",
    "        Zoomed in Region of interest [xstart,xstop,ystart,ystop]\n",
    "    aspect: int\n",
    "        Aspect ratio of the axes\n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear' or 'Asinh'\n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the color bar. Defualt is DN/s for countrate images\n",
    "    cmap: str\n",
    "        Color Map for plot\n",
    "    \"\"\"\n",
    "    #-----------------------------------------Scaling Information----------------------------------------\n",
    "    \n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "    \n",
    "    #--------------------------------------------Set Up Figure-------------------------------------------\n",
    "\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap=cmap)\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    #Zoom in on a portion of the image? \n",
    "    if zoom_in:\n",
    "        #inset axis \n",
    "        axins = ax.inset_axes([0.5, 0.6, 0.5, 0.3])\n",
    "        \n",
    "        axins.imshow(data_2d, origin=\"lower\", norm=norm, aspect=aspect, cmap=cmap)\n",
    "        \n",
    "        # subregion of the original image\n",
    "        axins.set_xlim(zoom_in[0], zoom_in[1])\n",
    "        axins.set_ylim(zoom_in[2], zoom_in[3])\n",
    "        axins.set_xticklabels([])\n",
    "        axins.set_yticklabels([])\n",
    "        ax.indicate_inset_zoom(axins, color=\"black\",edgecolor=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b1838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ifu_cubeslices(s3d_file_list, wavelength_slices=[], spaxel_locs=[], y_scale=None, cmap='jet', vmin_vmax = [[[0,15e1]]], save_figure=False, title=None, title_font = 30):\n",
    "    \"\"\"\n",
    "    Function to that takes a 3-D IFU data cube and generates: \n",
    "    \n",
    "    > 2-D cube slices based on wavelength (microns)\n",
    "    > Associated 1-D spectrum for a designated spaxel (spatial pixel) in the data cube\n",
    "    > Corresponding 3-D weight image giving the relative weights of the output spaxels\n",
    "    \n",
    "    Note: This function can accomidate multiple detectors plotted side-by-side. \n",
    "    The general format would follow [[detector 1 info], [detector 2 info]].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3d_file_list: list of str\n",
    "        3-D IFU data cube fits file list \n",
    "    wavelength_slices: tuple\n",
    "        List of wavelength values (microns) at which to create 2-D slices. \n",
    "    spaxel_locs: tuple\n",
    "        List of spaxel locations in which to plot the associated 1-D spectrum. (One spaxel location per slice)\n",
    "    y_scale: tuple\n",
    "        Y-axis limits for the associated 1-D spectrum of the spaxel. Default is to use the ymin and ymax of the data. \n",
    "    cmap: str\n",
    "        Color Map \n",
    "    vmin_vmax: tuple\n",
    "        Minimum & Maximum signal value to use for scaling (e.g., [[[vmin,vmax],[vmin,vmax]], [[vmin,vmax], [vmin,vmax]]])\n",
    "    title: str\n",
    "        Figure Title. Default is None. \n",
    "    title_font:int\n",
    "        Title Font Size\n",
    "    save_figure: bool\n",
    "        Save figure?         \n",
    "    \"\"\"\n",
    "    \n",
    "    #---------------------------------------------- Set-up Figure -------------------------------------------------\n",
    "\n",
    "    #Plot Slices From the Cube\n",
    "    fig = plt.figure(figsize=(8*np.array(wavelength_slices).size,18))\n",
    "    gs = grd.GridSpec(3, np.array(wavelength_slices).size, height_ratios=[1]*3, width_ratios=[1]*np.array(wavelength_slices).size, hspace=0.4,wspace=0.7)\n",
    "\n",
    "    total_num_plots=3*np.array(wavelength_slices).size\n",
    "    \n",
    "    plot_count = 0\n",
    "    #---------------------------------------------Open Files------------------------------------------------------\n",
    "    \n",
    "    for s3d_file in s3d_file_list:\n",
    "        \n",
    "        root=s3d_file[:-9] #Root file name \n",
    "        print(s3d_file)\n",
    "        s3d = fits.open(s3d_file) #3-D IFU data cube fits file \n",
    "        x1d3 = datamodels.open(root+'_x1d.fits') #1-D Extracted Spectrum            \n",
    "    \n",
    "        #--------------------------------Wavelength & Surface Brightness/Flux Arrays------------------------------\n",
    "    \n",
    "        x1d3wave = x1d3.spec[0].spec_table.WAVELENGTH\n",
    "            \n",
    "        #--------------------------------------Data & Header Information------------------------------------------\n",
    "\n",
    "    \n",
    "        #SCI Extension: [Type:ImageHDU  Cards:92   Dimensions:(57, 61, 973)   Format:float32]\n",
    "        cube = s3d[1].data #Science data\n",
    "        wcs = WCS(s3d[1].header) #World Coordinate System (WCS) Transformation keywords \n",
    "        wmap = s3d[4].data #3-D weight image giving the relative weights of the output spaxels.\n",
    "        cdelt1 = s3d[1].header['CDELT1']*3600. #Axis 1 coordinate increment at reference point \n",
    "        cdelt2 = s3d[1].header['CDELT2']*3600. #Axis 2 coordinate increment at reference point \n",
    "        cdelt3 = s3d[1].header['CDELT3'] #Axis 3 coordinate increment at reference point \n",
    "        crval3 = s3d[1].header['CRVAL3'] #third axis value at the reference pixel  \n",
    "\n",
    "        #Wavelength range of the grating/filter combination\n",
    "        wavstart = s3d[1].header['WAVSTART']\n",
    "        wavend = s3d[1].header['WAVEND']\n",
    "        s3d.close()\n",
    "    \n",
    "        #---------------------------------------------------Plots-------------------------------------------------\n",
    "        \n",
    "        cmap_custom = cm.colors.LinearSegmentedColormap.from_list(\"\", [\"darkred\",\"darkturquoise\",\"blue\"])\n",
    "        colors = cmap_custom(np.linspace(0, 1, np.array(wavelength_slices).size))\n",
    "\n",
    "        #To Account for if NRS1 & NRS2 are both being plotted Side-by-side\n",
    "        if len(wavelength_slices) != 1:\n",
    "            if 'nrs1' in s3d_file:\n",
    "                wavelengths = wavelength_slices[0]\n",
    "                spaxel_loc = spaxel_locs[0]\n",
    "                vmin_vmax_vals = vmin_vmax[0]\n",
    "                \n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            elif 'nrs2' in s3d_file:\n",
    "                wavelengths = wavelength_slices[1]\n",
    "                spaxel_loc = spaxel_locs[1]\n",
    "                vmin_vmax_vals = vmin_vmax[1]\n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[1]\n",
    "\n",
    "        else:\n",
    "            wavelengths = wavelength_slices[0]\n",
    "            spaxel_loc = spaxel_locs[0]\n",
    "            vmin_vmax_vals = vmin_vmax[0]\n",
    "            if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            \n",
    "        #Loop through each wavelength slices\n",
    "        for i, wave_slice in enumerate(wavelengths):\n",
    "\n",
    "            if float(wavstart)<=wave_slice*10**-6<=float(wavend):\n",
    "                \n",
    "                #--------------------------------------------2-D Cube Slice------------------------------------------------\n",
    "            \n",
    "                #Min & Max Image Values & Scaling\n",
    "                if len(vmin_vmax_vals) != 1:\n",
    "                    vmax_val = vmin_vmax_vals[i][1]\n",
    "                    vmin_val = vmin_vmax_vals[i][0]\n",
    "                else:\n",
    "                    vmax_val = vmin_vmax_vals[0][1]\n",
    "                    vmin_val = vmin_vmax_vals[0][0]\n",
    "\n",
    "                slicewave = wave_slice\n",
    "                nslice = int((slicewave - crval3)/cdelt3) #the slice of the cube we want to plot\n",
    "                ax1 = plt.subplot(gs[0+plot_count], projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "\n",
    "                slice_mean = np.nanmean(cube[(nslice-2):(nslice+2), :, :], axis=0) #Mean of the slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm=ImageNormalize(slice_mean, vmin=vmin_val, vmax=vmax_val, stretch=AsinhStretch()) #normalize &stretch \n",
    "                slice_image= ax1.imshow(slice_mean, norm=slice_norm, origin='lower', aspect='auto',cmap=cmap) #plot slice\n",
    "\n",
    "                cb_image = fig.colorbar(slice_image, fraction=0.046, pad=0.04)\n",
    "                cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 22)\n",
    "                cb_image.ax.tick_params(labelsize=20)\n",
    "                cb_image.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax1.set_xlabel('RA', fontsize =22)\n",
    "                ax1.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                ax1.set_title('Detector {} \\n Grating/Filter: {}/{} \\n {} microns'.format(s3d[0].header['DETECTOR'],s3d[0].header['GRATING'], s3d[0].header['FILTER'], str(slicewave)), fontsize =25)\n",
    "                ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax1.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "               \n",
    "                #------------------------------------------Spaxel 1-D Spectrum---------------------------------------------\n",
    "                \n",
    "                #Zoom in on a Spaxel: Spectrum\n",
    "                loc = [spaxel_loc[i][0],spaxel_loc[i][1]]\n",
    "                x1d3flux_loc = cube[:, loc[1], loc[0]]\n",
    "                ax2 = plt.subplot(gs[int(total_num_plots/3)+plot_count])\n",
    "\n",
    "                #Spaxel Box Highlight \n",
    "                spaxel_rect = plt.Rectangle((loc[0]-.5, loc[1]-.5), 1,1, fill=False, color='black', linewidth=2)\n",
    "                ax1.add_patch(spaxel_rect)\n",
    "                \n",
    "                ax2.plot(x1d3wave, x1d3flux_loc, linewidth=1, color=colors[i])\n",
    "                ax2.grid(linewidth=2)\n",
    "                ax2.set_xlabel('$\\u03BB [\\u03BC$m]',fontsize=22)\n",
    "                ax2.set_ylabel(\"Surface Brightness \\n (MJy/sr)\",fontsize=22)\n",
    "                ax2.set_title('Spaxel at (x, y)='+repr(loc), fontsize=25)\n",
    "                ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax2.yaxis.get_offset_text().set_fontsize(15)\n",
    "                \n",
    "                #Scale Information\n",
    "                if y_scale:\n",
    "                    ymin, ymax = y_scales[i][0], y_scales[i][1]\n",
    "                else:\n",
    "                    ymin, ymax = ax2.set_ylim()\n",
    "                \n",
    "                ax2.set_ylim(ymin, ymax)\n",
    "                ax2.xaxis.set_tick_params(labelsize=20)\n",
    "                ax2.yaxis.set_tick_params(labelsize=20)\n",
    "                ax2.set_aspect(0.5/ax2.get_data_ratio())\n",
    "                \n",
    "                #-----------------------------------------------Weight Map-------------------------------------------------\n",
    "                \n",
    "                #Corresponding Weight Map (wmap) for Cube Slice\n",
    "                ax3 = plt.subplot(gs[int(total_num_plots)-np.array(wavelength_slices).size+plot_count], projection=wcs, slices=('x', 'y', nslice)) #set up the subplot space\n",
    "                \n",
    "                slice_mean_wmap = np.nanmean(wmap[(nslice-2):(nslice+2), :, :], axis=0) #Mean of the wmap slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_norm_wmap=ImageNormalize(slice_mean_wmap, stretch=AsinhStretch()) #normalize &stretch\n",
    "                slice_wmap = ax3.imshow(slice_mean_wmap, norm=slice_norm_wmap, origin='lower',aspect='auto', cmap=cmap) #plot slice\n",
    "\n",
    "                cb_wmap = fig.colorbar(slice_wmap, fraction=0.046, pad=0.04)\n",
    "                cb_wmap.set_label('Weight', labelpad=-1, fontsize = 22)\n",
    "                cb_wmap.ax.tick_params(labelsize=20)\n",
    "                cb_wmap.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "                \n",
    "                ax3.set_xlabel('RA', fontsize=22)\n",
    "                ax3.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                #ax3.grid(color='gray', ls='solid')\n",
    "                ax3.set_title(str(slicewave)+' microns: Weight Map', fontsize=25)\n",
    "                ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax3.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                plot_count += 1\n",
    "                    \n",
    "            else:\n",
    "                None\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=title_font)\n",
    "        plt.subplots_adjust(top=0.8) \n",
    "\n",
    "    if save_figure == True:\n",
    "        fig.savefig(root+\".png\",dpi=24, bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a9a54",
   "metadata": {},
   "source": [
    "## 4. Directory Set-Up and defining some base parameters <a id='dir_setup'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note: For this JWebbinar we pre-computed **all but one** products for [calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) and [calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipelin/calwebb_spec2.html#calwebb-spec2) to save time. Those will be copied into the output folder. If `jwebbinar = False` **ALL** products are created, which can take a significant amount of time. For [calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3) this is not possible since all products are needed to create the final datacube.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c870b4c4-bc8d-48d8-8f19-ec3d54d1f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JWebbinar is deactivated: ALL OBSERATIONS WILL BE REDUCED!!!\n"
     ]
    }
   ],
   "source": [
    "jwebbinar = False\n",
    "\n",
    "if not jwebbinar:\n",
    "    print('')\n",
    "    print('JWebbinar is deactivated: ALL OBSERATIONS WILL BE REDUCED!!!')\n",
    "\n",
    "hub_root = \"/Users/nayera/my_jwebbinar_prep/jwebbinar28/preloaded-fits\"\n",
    "user_root = \"/Users/nayera/my_jwebbinar_prep/jwebbinar28/outputs\"\n",
    "\n",
    "#basedir = os.path.join(os.getcwd(),'nirspec_ifu_point_source')\n",
    "basedir_in = os.path.join(hub_root,'nirspec_ifu_point_source')\n",
    "basedir_out = os.path.join(user_root, 'nirspec_ifu_point_jwebbinar28')\n",
    "\n",
    "output_dir = os.path.join(basedir_out,'run_folder')\n",
    "mast_products_dir = os.path.join(basedir_in,'mast_products')\n",
    "pre_computed_run_dir = os.path.join(basedir_in,'pre_computed_run')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(mast_products_dir):\n",
    "    os.makedirs(mast_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce722a1-a3b0-4766-8ec4-3f4e48e27489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nayera/my_jwebbinar_prep/jwebbinar28/preloaded-fits/nirspec_ifu_point_source/mast_products'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mast_products_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad59a3-6297-4c6b-b379-ea79701985d9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note: To allow everyone to get the same results we fixed the used PMAP to `jwst_1146.pmap`. To save download time we also provide the CRDS cache and to not overwrite any of your systems settings we saved the cache in  \"../crds_cache\". The following commands\n",
    "`os.environ['CRDS_PATH'] = \"../crds_cache\"`, and\n",
    "`os.environ['CRDS_CONTEXT'] = 'jwst_1146.pmap'`\n",
    "overwrite the system settings for **THIS NOTEBOOK ONLY**. To run the notebook with the latest reference files these two lines should be commented out\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "564b30de-7c75-4568-846a-74b3dfba2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up the CRDS-cache and pmap\n",
      "CRDS-cache is set to: /Users/nayera/crds_cache\n",
      "Current activated CRDS Context = jwst_1146.pmap\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print(\"Setting up the CRDS-cache and pmap\")\n",
    "\n",
    "'''\n",
    "The following should be uncommented to used the already cached files to save \n",
    "download time. Set if different to default set in bash_rc file. The CRDS_CONTEXT\n",
    "ensures that everybody uses the same pmap for this exercise.\n",
    "This MUST commented out to ensure that the latest reference files in CRDS\n",
    "will be used\n",
    "'''\n",
    "os.environ['CRDS_PATH'] = \"/Users/nayera/crds_cache\" \n",
    "os.environ['CRDS_CONTEXT'] = 'jwst_1146.pmap' ### \n",
    "\n",
    "print('CRDS-cache is set to:', os.getenv('CRDS_PATH'))\n",
    "print(\"Current activated CRDS Context = {}\".format(os.getenv('CRDS_CONTEXT')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6ed15",
   "metadata": {},
   "source": [
    "## 5. Download the Data <a id='data'></a>\n",
    "\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "| Target: NGC 7319 AGN |       |   |   |   |\n",
    "|:-----------:|:-------:|---|---|---|\n",
    "| Proposal ID | 02732 |   |   |   |\n",
    "| [GRATING/FILTER](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-observing-modes/nirspec-ifu-spectroscopy)   | PRISM/CLEAR | λ: 0.6–5.3 μm (a low resolution, R ~ 100) |   |   |\n",
    "|   DURATION  | 160.478 [s] | Total duration of one exposure |   |   |   |\n",
    "|   READPATT  | NRSIRS2RAPID | Readout Pattern |   |   |   |\n",
    "|   PATTTYPE  | CYCLING | Primary dither pattern type |   |   |\n",
    "|   PATTSIZE  | LARGE | Primary dither pattern size (1.0\" extent) |   |   |\n",
    "|   NUMDTHPT  | 8 | Total number of points in pattern |   |   | \n",
    "|   SRCTYAPT  | UNKNOWN | Source Type selected in APT |   |   | \n",
    "\n",
    "MAST products are saved to a folder called `mast_products` within the designated output directory defined earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f2e743-1cd1-4d41-b67b-094cb24a4ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 out of range for table with length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m obs_table \u001b[38;5;241m=\u001b[39m Observations\u001b[38;5;241m.\u001b[39mquery_criteria(target_name\u001b[38;5;241m=\u001b[39mtarget_name)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print out the available observations\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mobs_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/table/table.py:2095\u001b[0m, in \u001b[0;36mTable.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[item]\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m-> 2095\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   2097\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(item, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m () \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2098\u001b[0m ):\n\u001b[1;32m   2099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRow(\u001b[38;5;28mself\u001b[39m, item\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/table/row.py:41\u001b[0m, in \u001b[0;36mRow.__init__\u001b[0;34m(self, table, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(table)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mn \u001b[38;5;129;01mor\u001b[39;00m index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of range for table with length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(table)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Finally, ensure the index is positive [#8422] and set Row attributes\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m%\u001b[39m n\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 out of range for table with length 0"
     ]
    }
   ],
   "source": [
    "from astroquery.mast import Observations\n",
    "\n",
    "# Define the target (NGC 7319 AGN)\n",
    "target_name = \"NGC 7319 AGN\"\n",
    "\n",
    "\n",
    "# Query MAST for observations of NGC 7319 AGN\n",
    "obs_table = Observations.query_criteria(target_name=target_name)\n",
    "\n",
    "# Print out the available observations\n",
    "print(obs_table[0])\n",
    "\n",
    "# Download the data\n",
    "# You can either download specific products or all available products\n",
    "# Here, we assume the first observation's products are of interest:\n",
    "#obs_id = obs_table['obs_id'][0]  # Select the first observation's ID\n",
    "#products = Observations.get_product_list(obs_table[obs_table['obs_id'] == obs_id])\n",
    "\n",
    "# Download the products (if there are multiple, you may want to check)\n",
    "#Observations.download_products(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30347914",
   "metadata": {},
   "source": [
    "## 6. Products Found In MAST <a id='mast_products'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "Here we show and plot the products as they are provided in MAST. This will also demonstrate why in most science cases reprocessing the data is needed.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> To optimally use your science data some parameters need to be uniquly tweaked specifically for your observations. No parameter setting wil be sufficient for **all** data.\n",
    "    \n",
    "</div> \n",
    "\n",
    "> In [APT](https://jwst-docs.stsci.edu/jwst-astronomers-proposal-tool-overview), the observer has three options for source type (`SRCTYAPT` keyword): `POINT`, `EXTENDED`, or `UNKNOWN`. In stage 2, the `srctype` step will first check if the `SRCTYAPT` keyword is present and populated. If `SRCTYAPT` is not present or is set to `UNKNOWN`, the step determines a suitable value based on the observing mode, command line input, and other characteristics of the exposure. If the exposure is identified as a background exposure (`BKGDTARG = True`), the exposures default to a source type of `EXTENDED`. Exposures that are part of a nodded pattern (identified by keyword `PATTYPE`), which are assumed to only be used with point-like targets, default to a source type of `POINT`. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/srctype/description.html#single-source-observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a5889",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please be aware that many exposures are suffering from snowballs (see NRS2 in the above plot) which are caused by large cosmic ray events (https://jwst-docs.stsci.edu/data-artifacts-and-features/snowballs-and-shower-artifacts). To mitigate this ``expand_large_events`` needs to be set to `True` in the jump_detection algorithm of the `callwebb_detector1` step. This is currently deactivate by default hence a rerun is needed. This is especially important for deep exposures with long integration times. A rough estimate is 1 snowball per detector per 20s.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d54809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products found in MAST used JWST calibration pipeline version: 1.16.1 and jwst_1303.pmap\n"
     ]
    }
   ],
   "source": [
    "#Just a check to see what verison of the pipeline and what pmap was used\n",
    "x1d3_mast = fits.open(glob.glob(os.path.join(mast_products_dir, '*_x1d.fits'))[0])\n",
    "\n",
    "print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\".format(x1d3_mast[0].header['CAL_VER'],x1d3_mast[0].header['CRDS_CTX']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a8837",
   "metadata": {},
   "source": [
    "## 7. Re-processing the Data <a id='reprocessing'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Many parameter we show in the below examples are set to the default ones. This should only provide an overview over some of the most common parameters that can be adjusted to get the best out of the science **but** often they require a few iterations to find the best possible parameter set for a given observation. \n",
    "</div>\n",
    "\n",
    "Due to lengthy processing times, only one exposure of will be re-processed in this demonstration if `jwebbinar=True`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126569cf",
   "metadata": {},
   "source": [
    "### 7.1 Stage 1 Rerun & Products  <a id='level1_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> The most notebale difference to the MAST products will be the snowball rejection, which are large cosmic ray event. This can be acomplished setting `\"expand_large_events\": True` in the `jump` step. Setting the `\"expand_factor\": 3` seems to be a good value for NIRSpec observations to cover most snowballs. A manual check of the rate files is recommended.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651021b3-6911-4e1a-98f7-0dce85dd92cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDS Cache Path: /Users/nayera/crds_cache\n",
      "CRDS Server: https://jwst-crds.stsci.edu\n",
      "NumPy Version: 1.25.2\n",
      "ASDF Version: 2.15.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import asdf\n",
    "\n",
    "import os\n",
    "os.environ[\"CRDS_SERVER\"] = \"https://jwst-crds.stsci.edu\"\n",
    "\n",
    "# Check CRDS Cache Path\n",
    "crds_cache = os.getenv('CRDS_PATH', 'CRDS_PATH environment variable not set')\n",
    "print(f\"CRDS Cache Path: {crds_cache}\")\n",
    "\n",
    "# Check CRDS Server\n",
    "crds_server = os.getenv('CRDS_SERVER', 'CRDS_SERVER environment variable not set')\n",
    "print(f\"CRDS Server: {crds_server}\")\n",
    "\n",
    "# Check NumPy Version\n",
    "numpy_version = np.__version__\n",
    "print(f\"NumPy Version: {numpy_version}\")\n",
    "\n",
    "# Check ASDF Version\n",
    "asdf_version = asdf.__version__\n",
    "print(f\"ASDF Version: {asdf_version}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e624ce66-c24d-4206-9dc1-784efbcd2d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Stage 1 Corrections & Calibrations to: jw02732003001_02101_00002_nrs1_uncal.fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 16241408 into shape (1,10,3200,2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uncal_file \u001b[38;5;129;01min\u001b[39;00m filelist: \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying Stage 1 Corrections & Calibrations to: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(uncal_file))\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mDetector1Pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43muncal_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msave_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjump\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand_large_events\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m### this activates the snowball rejection\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximum_cores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m### you can limit the number of used CPUs here\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand_factor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m### the non default value 3 seems to be better for NIRSpec to mask the full region\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"rejection_threshold\": 4.0,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"four_group_rejection_threshold\": 5.0,\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"flag_4_neighbors\": True,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"max_jump_to_flag_neighbors\": 200,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"min_jump_to_flag_neighbors\": 10,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"edge_size\": 4,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"sat_expand\": 0.,\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"sat_required_snowball\": False,\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;66;43;03m# \"min_jump_area\": 2.,\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrefpix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43modd_even_columns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;66;43;03m# \"use_side_ref_pixels\": True,\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;66;43;03m# \"side_smoothing_lenght\": 11,\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;66;43;03m# \"side_gain\": 1.0,\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43movr_corr_mitigation_ftr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mramp_fit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuppress_one_group\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximum_cores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaturation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_pix_grow_sat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                             \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jwebbinar \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     pre_computed_filelist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pre_computed_run_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*_rate*.fits\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stpipe/step.py:636\u001b[0m, in \u001b[0;36mStep.call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    635\u001b[0m     filename \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 636\u001b[0m config, config_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stpipe/step.py:1362\u001b[0m, in \u001b[0;36mStep.build_config\u001b[0;34m(cls, input, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m log_cls \u001b[38;5;241m=\u001b[39m log\u001b[38;5;241m.\u001b[39mgetLogger(logger_name)\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[0;32m-> 1362\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_from_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1364\u001b[0m     log_cls\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo filename given, cannot retrieve config from CRDS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stpipe/pipeline.py:183\u001b[0m, in \u001b[0;36mPipeline.get_config_from_reference\u001b[0;34m(cls, dataset, disable, crds_observatory)\u001b[0m\n\u001b[1;32m    180\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieving all substep parameters from CRDS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Iterate over the steps in the pipeline\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datamodels_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masn_n_members\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m model:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Sequence):\n\u001b[1;32m    185\u001b[0m         crds_parameters \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_models[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_crds_parameters()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/jwst/stpipe/core.py:28\u001b[0m, in \u001b[0;36mJwstStep._datamodels_open\u001b[0;34m(cls, init, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_datamodels_open\u001b[39m(\u001b[38;5;28mcls\u001b[39m, init, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatamodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/jwst/datamodels/util.py:226\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(init, guess, memmap, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Actually open the model\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mnew_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_to_close \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/model_base.py:224\u001b[0m, in \u001b[0;36mDataModel.__init__\u001b[0;34m(self, init, schema, memmap, pass_invalid_values, strict_validation, validate_on_assignment, cast_fits_arrays, validate_arrays, ignore_missing_extensions, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, fits\u001b[38;5;241m.\u001b[39mHDUList):\n\u001b[1;32m    223\u001b[0m     init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_migrate_hdulist(init)\n\u001b[0;32m--> 224\u001b[0m     asdffile \u001b[38;5;241m=\u001b[39m \u001b[43mfits_support\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fits\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, PurePath)):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, PurePath):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/fits_support.py:708\u001b[0m, in \u001b[0;36mfrom_fits\u001b[0;34m(hdulist, schema, context, skip_fits_update, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Determine whether skipping the FITS loading can be done.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m skip_fits_update \u001b[38;5;241m=\u001b[39m _verify_skip_fits_update(\n\u001b[1;32m    705\u001b[0m     skip_fits_update, hdulist, ff, context\n\u001b[1;32m    706\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m known_keywords, known_datas \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhdulist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_fits_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_fits_update\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_fits_update:\n\u001b[1;32m    712\u001b[0m     _load_extra_fits(hdulist, known_keywords, known_datas, ff\u001b[38;5;241m.\u001b[39mtree)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/fits_support.py:628\u001b[0m, in \u001b[0;36m_load_from_schema\u001b[0;34m(hdulist, schema, tree, context, skip_fits_update)\u001b[0m\n\u001b[1;32m    622\u001b[0m                 recurse(schema[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    623\u001b[0m                         path \u001b[38;5;241m+\u001b[39m [i],\n\u001b[1;32m    624\u001b[0m                         combiner,\n\u001b[1;32m    625\u001b[0m                         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhdu_index\u001b[39m\u001b[38;5;124m'\u001b[39m: i})\n\u001b[1;32m    626\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m \u001b[43mmschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m known_keywords, known_datas\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/schema.py:149\u001b[0m, in \u001b[0;36mwalk_schema\u001b[0;34m(schema, callback, ctx)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 149\u001b[0m \u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# testing memory usage and garbage collection revealed that recurse\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# was diffcult to garbage collect (often resulting in models and associated\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# data ending up in generation 2 for the garbage collector).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# see the following PR for more information\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# https://github.com/spacetelescope/stdatamodels/pull/109\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m recurse\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/schema.py:137\u001b[0m, in \u001b[0;36mwalk_schema.<locals>.recurse\u001b[0;34m(schema, path, combiner, ctx)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 137\u001b[0m         \u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombiner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    140\u001b[0m     items \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/schema.py:124\u001b[0m, in \u001b[0;36mwalk_schema.<locals>.recurse\u001b[0;34m(schema, path, combiner, ctx)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecurse\u001b[39m(schema, path, combiner, ctx):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombiner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# noqa: F821\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallOf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/fits_support.py:606\u001b[0m, in \u001b[0;36m_load_from_schema.<locals>.callback\u001b[0;34m(schema, path, combiner, ctx, recurse)\u001b[0m\n\u001b[1;32m    602\u001b[0m             properties\u001b[38;5;241m.\u001b[39mput_value(path, result, tree)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfits_hdu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m schema \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_ndim\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m schema \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m schema \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatatype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m schema):\n\u001b[0;32m--> 606\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_fits_array_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhdulist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhdu_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_datas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39m_validate_on_assignment:\n\u001b[1;32m    610\u001b[0m         validate\u001b[38;5;241m.\u001b[39mvalue_change(path, result, schema, context)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/fits_support.py:558\u001b[0m, in \u001b[0;36m_fits_array_loader\u001b[0;34m(hdulist, schema, hdu_index, known_datas, context)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    557\u001b[0m known_datas\u001b[38;5;241m.\u001b[39madd(hdu)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_fits_hdu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cast_fits_arrays\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/stdatamodels/fits_support.py:786\u001b[0m, in \u001b[0;36mfrom_fits_hdu\u001b[0;34m(hdu, schema, cast_arrays)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_fits_hdu\u001b[39m(hdu, schema, cast_arrays\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    783\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;124;03m    Read the data from a fits hdu into a numpy ndarray\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhdu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cast_arrays:\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# Save the column listeners for possible restoration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_coldefs\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/utils/decorators.py:836\u001b[0m, in \u001b[0;36mlazyproperty.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    834\u001b[0m         val \u001b[38;5;241m=\u001b[39m obj_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key, _NotFound)\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NotFound:\n\u001b[0;32m--> 836\u001b[0m             val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m             obj_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/io/fits/hdu/image.py:250\u001b[0m, in \u001b[0;36m_ImageBaseHDU.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axes) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled_image_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_header_scale_info(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/io/fits/hdu/image.py:808\u001b[0m, in \u001b[0;36m_ImageBaseHDU._get_scaled_image_data\u001b[0;34m(self, offset, shape)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03mInternal function for reading image data from a file and apply scale\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;124;03mfactors to it.  Normally this is used for the entire image, but it\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03msupports alternate offset/shape for Section support.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    806\u001b[0m code \u001b[38;5;241m=\u001b[39m BITPIX2DTYPE[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig_bitpix]\n\u001b[0;32m--> 808\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m raw_data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m raw_data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_not_scale_image_data \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig_bzero \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig_bscale \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    813\u001b[0m ):\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;66;03m# No further conversion of the data is necessary\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/io/fits/hdu/base.py:559\u001b[0m, in \u001b[0;36m_BaseHDU._get_raw_data\u001b[0;34m(self, shape, code, offset)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray(shape, dtype\u001b[38;5;241m=\u001b[39mcode, buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file:\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/masterclass/lib/python3.10/site-packages/astropy/io/fits/file.py:410\u001b[0m, in \u001b[0;36m_File.readarray\u001b[0;34m(self, size, offset, dtype, shape)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(offset)\n\u001b[1;32m    409\u001b[0m         data \u001b[38;5;241m=\u001b[39m _array_from_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file, dtype, count)\n\u001b[0;32m--> 410\u001b[0m         data\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# Make sure we leave the file in the position we found it; on\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# some platforms (e.g. Windows) mmaping a file handle can also\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# reset its file pointer.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Also for Windows when using mmap seek() may return weird\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# negative values, which is fixed by calling tell() before.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 16241408 into shape (1,10,3200,2048)"
     ]
    }
   ],
   "source": [
    "#Stage 1 Processing \n",
    "jwebbinar = 1\n",
    "if jwebbinar == True:\n",
    "    filelist = sorted(glob.glob(os.path.join(mast_products_dir, '*02101*00002_nrs1_uncal.fits')))\n",
    "else:\n",
    "    filelist = sorted(glob.glob(os.path.join(mast_products_dir, '*nrs1_uncal.fits')))\n",
    "\n",
    "for uncal_file in filelist: \n",
    "    print(\"Applying Stage 1 Corrections & Calibrations to: \"+ os.path.basename(uncal_file))\n",
    "    \n",
    "    result = Detector1Pipeline.call(uncal_file,\n",
    "                                    save_results = True,\n",
    "                                    output_dir = output_dir,\n",
    "                                    steps = {\"jump\":{\"skip\": False,\n",
    "                                                     \"expand_large_events\": True, ### this activates the snowball rejection\n",
    "                                                     \"maximum_cores\": \"all\", ### you can limit the number of used CPUs here\n",
    "                                                     \"expand_factor\": 3, ### the non default value 3 seems to be better for NIRSpec to mask the full region\n",
    "                                                     # \"rejection_threshold\": 4.0,\n",
    "                                                     # \"four_group_rejection_threshold\": 5.0,\n",
    "                                                     # \"flag_4_neighbors\": True,\n",
    "                                                     # \"max_jump_to_flag_neighbors\": 200,\n",
    "                                                     # \"min_jump_to_flag_neighbors\": 10,\n",
    "                                                     # \"edge_size\": 4,\n",
    "                                                     # \"sat_expand\": 0.,\n",
    "                                                     # \"sat_required_snowball\": False,\n",
    "                                                     # \"min_jump_area\": 2.,\n",
    "                                                     \"save_results\": True,\n",
    "                                                     },\n",
    "                                             \"refpix\": {\"skip\": False,\n",
    "                                                        \"odd_even_columns\": True,\n",
    "                                                        # \"use_side_ref_pixels\": True,\n",
    "                                                        # \"side_smoothing_lenght\": 11,\n",
    "                                                        # \"side_gain\": 1.0,\n",
    "                                                        \"ovr_corr_mitigation_ftr\": 3.0\n",
    "                                                       },\n",
    "                                             \"ramp_fit\": {\"skip\": False,\n",
    "                                                         \"suppress_one_group\": False,\n",
    "                                                         \"maximum_cores\": 'all'\n",
    "                                                         },\n",
    "                                             \"saturation\": {\"skip\": False,\n",
    "                                                           \"n_pix_grow_sat\": 1\n",
    "                                                           },\n",
    "                                             \n",
    "                                             })\n",
    "\n",
    "\n",
    "if jwebbinar == False:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*_rate*.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6584ea94-8989-4977-a2da-613cbeffbcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: preloaded-fits/nirspec_ifu_point_source/mast_products/jw02732003001_02101_00001_nrs1_cal.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU     356   ()      \n",
      "  1  SCI           1 ImageHDU        73   (2048, 2048)   float32   \n",
      "  2  ERR           1 ImageHDU        10   (2048, 2048)   float32   \n",
      "  3  DQ            1 ImageHDU        11   (2048, 2048)   int32 (rescales to uint32)   \n",
      "  4  VAR_POISSON    1 ImageHDU         9   (2048, 2048)   float32   \n",
      "  5  VAR_RNOISE    1 ImageHDU         9   (2048, 2048)   float32   \n",
      "  6  VAR_FLAT      1 ImageHDU         9   (2048, 2048)   float32   \n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "uncal_file = \"preloaded-fits/nirspec_ifu_point_source/mast_products/jw02732003001_02101_00001_nrs1_cal.fits\"\n",
    "with fits.open(uncal_file) as hdul:\n",
    "    hdul.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da176563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 slope products -- level 2a images\n",
    "\n",
    "#Plot 1 dither position\n",
    "\n",
    "file = glob.glob(os.path.join(output_dir, '*00001_nrs1_rate.fits'))[0]\n",
    "print(\"rate file: \", file)\n",
    "\n",
    "ratefile_open = datamodels.open(file)\n",
    "ratefile_sci = ratefile_open.data #get the pixel data (the SCI extension of the fits file)\n",
    "ratefile_dq = ratefile_open.dq #data quality map data (DQ extension)\n",
    "             \n",
    "show_image(ratefile_sci, 0,10, units='DN/s',zoom_in=[500,550, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Countrate Image \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) #rate files have units of DN/s\n",
    " \n",
    "show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',zoom_in=[500,550, 1250,1300], ysize=20, xsize=20,\n",
    "           title='Data Quality Map \\n Detector: {} \\n 8-Cycle Dither Position Index: {} \\n GRATING/FILTER: {}/{}'.format(ratefile_open.meta.instrument.detector,\n",
    "                                                                                                                        ratefile_open.meta.dither.position_number, \n",
    "                                                                                                                        ratefile_open.meta.instrument.grating,\n",
    "                                                                                                                        ratefile_open.meta.instrument.filter)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c9f5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Compared to the [countrate (slope) products found in MAST](#level1_mast), fewer pixels are flagged as Do Not Use when using the most up-to-date pmap in CRDS (at the time jwst_1106.pmap). With the latest pmap, one can observe low-level vertical banding in the central regions of the detector, and the \"picture frame\" towards the edge of both detectors, where there is less correlated read noise a lot easier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf378c9d",
   "metadata": {},
   "source": [
    "### 7.2 Stage 2  <a id='stage2'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "This IFU data set focuses on an AGN target, which has a compact region at the center of its galaxy that can be considered a point source. To treat this IFU data as a point source, one must change the `SRCTYPE=POINT` header keyword in the `cal.fits` files before running stages 2 and 3 of the calibration pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268fa96-01fc-496b-a794-48a000b8b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating the IFU data as a point source \n",
    "#To run as a point source, alter the rate file header keywrod SRCTYAPT=POINT & rerun stage 2 of the pipeline \n",
    "#Loop through the copied rate files and update the source type keyword\n",
    "for rate_file in sorted(glob.glob(os.path.join(output_dir, '*nrs1_rate.fits'))):\n",
    "    rate_file_hdu = fits.open(rate_file, 'update')\n",
    "    \n",
    "    #Change source type to point \n",
    "    rate_file_hdu[0].header['SRCTYAPT'] = 'POINT'\n",
    "    rate_file_hdu.close()\n",
    "\n",
    "    print(\"Changed file: \", rate_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd042310-1379-484b-a0dd-65bbf207c628",
   "metadata": {},
   "source": [
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources (as of DMS build 9.3/CAL_VER 1.10.2). For IFU point sources, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file: \n",
    "\n",
    "> For a point source, the spectrum is extracted using circular aperture photometry, **optionally (automatically) including background subtraction** using a circular annulus. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    "\n",
    "When processing the IFU as a point source, the `extract_1d` step will automatically apply background subtraction unless otherwise told not to. The `extract_1d` step will also use the default circular extraction apertures for the source and background, an example of how to modify the EXTRACT1D reference file can be found at the end of this notebook.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note there has been a bug in the `cube_build` step that caused the point source flux to not be conserved when using different spatial sampling. A fix has been implemented as of release DMS build 9.3/CAL_VER 1.10.2. In order to enable the correct functionality, the units of the cal.fits files and cubes will now be in surface brightness, and only the 1-D extracted spectra will be in units of Jy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a6aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stage 2 Processing \n",
    "\n",
    "\n",
    "if jwebbinar == True:\n",
    "    filelist = sorted(glob.glob(os.path.join(output_dir, '*02101*00001*nrs1*rate.fits')))\n",
    "else:\n",
    "    filelist = sorted(glob.glob(os.path.join(output_dir, '*nrs1_rate.fits')))\n",
    "\n",
    "#Process each rate file seperately \n",
    "for rate_file in filelist:\n",
    "        \n",
    "    print(\"Applying Stage 2 Calibrations & Corrections to: \"+ os.path.basename(rate_file))\n",
    "    \n",
    "    result = Spec2Pipeline.call(rate_file,\n",
    "                                save_results = True,\n",
    "                                output_dir = output_dir,\n",
    "                                steps = {\"msa_flagging\":{\"skip\": False   ### Masks those pixels that are affected by stuck open MSA shutters\n",
    "                                                         },\n",
    "                                         \"imprint_subtract\":{\"skip\": True    ### This step is needed if LEAKCAL observations were provided\"\n",
    "                                                    },\n",
    "                                         \"bkg_subtract\":{\"skip\": True,    ### This step is needed if background observations were provided\n",
    "                                                       \"sigma\": 3,\n",
    "                                                       \"maxiters\": None,\n",
    "                                                       \"save_combined_background\": False\n",
    "                                                       },\n",
    "                                          \"flat_field\":{\"skip\": False,\n",
    "                                                        \"save_interpolated_flat\": False   ### A flag to indicate whether to save to a file the NIRSpec flat field that was constructed on-the-fly by the step.\n",
    "                                                        },\n",
    "                                         \"pathloss\":{\"skip\": False\n",
    "                                                     },\n",
    "                                         \"photom\":{\"skip\": False   ### photmetric calibration \n",
    "                                                   },\n",
    "                                         \"cube_build\":{\"skip\": False    ### builds the 3D cube for each exposure. This is not necessary in the Spec2 step unless you want to inspect the individual cubes before combining them\n",
    "                                                       },\n",
    "                                         \"extract_1d\":{\"skip\": False   ### Extracts the 1D spectra for each exposure . Is not necessary in the Spec2 step unless you want to inspect the individual extracted spectra\n",
    "                                                       }\n",
    "                                         }\n",
    "                                )\n",
    "\n",
    "if jwebbinar == True:\n",
    "\n",
    "    pre_computed_filelist = sorted(glob.glob(os.path.join(pre_computed_run_dir, '*_cal*.fits')))\n",
    "    for file in pre_computed_filelist:\n",
    "        output = os.path.join(output_dir, os.path.basename(file))\n",
    "        print(file, ' => ', output)\n",
    "        shutil.copy(file, output)\n",
    "\n",
    "print(\"Hurray ...  this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2 Products -- Calibrated 3-D data cubes for three different wavelengths\n",
    "\n",
    "#Plotting the 4th (out of 8) dither position for both NRS1 and NRS2\n",
    "s3d_stage2_list = sorted(glob.glob(os.path.join(output_dir, '*00001_nrs?_s3d.fits')))\n",
    "\n",
    "title_stage2_rerun='NGC 7319 AGN \\n Level 2 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "nrs1_wavelengths = [1.4,3.3,4.5] #Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_spaxel_locs = [[30,29],[28,39],[14,25]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage2_list, wavelength_slices=[nrs1_wavelengths], \n",
    "                    spaxel_locs=[nrs1_spaxel_locs], title=title_stage2_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac83a4",
   "metadata": {},
   "source": [
    "### 7.3 Stage 3 Rerun & Products  <a id='level3_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "***Level 3 ASN File***\n",
    "\n",
    "> Observations that use a nod-type/dither patterns, their exposures are related. [Association files (ASN)](https://jwst-pipeline.readthedocs.io/en/stable/jwst/associations/overview.html) describe how multiple exposures are related to one another and how they depend on one another. Processing an ASN file permits exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than individual objects. IFU exposures taken with a dither pattern are not used for pixel-to-pixel background subtraction by the calibration pipeline (unlike exposures taken with a nod pattern).\n",
    "\n",
    "Therefore, all calibration files (`cal.fits`) in our spec3 ASN file should be labeled as science exposures (`exptype: science`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ea47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy ASN file from MAST\n",
    "\n",
    "asnfiles_mast = glob.glob(os.path.join(mast_products_dir, '*_spec3_*_asn.json')) #ASN file found in MAST\n",
    "print(mast_products_dir)\n",
    "print(asnfiles_mast)\n",
    "\n",
    "for file in asnfiles_mast:\n",
    "\n",
    "    asnfile_dest = os.path.join(output_dir, os.path.basename(file))\n",
    "    \n",
    "    print(file, \" => \" , asnfile_dest)\n",
    "    shutil.copy(file, asnfile_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebc610-ab4d-4321-a323-1b5461cfed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show the ASN file for which we will run CalSpec3\n",
    "\n",
    "asnfile = glob.glob(os.path.join(output_dir, '*_spec3_00001_asn.json'))[0]\n",
    "\n",
    "with open(asnfile, 'r') as f_obj:\n",
    "    asnfile_data = json.load(f_obj)\n",
    "        \n",
    "JSON(asnfile_data, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3669d28",
   "metadata": {},
   "source": [
    "#### 7.3.1 New Outlier Detection Algorithm<a id='outlier_detection_new'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "The new outlier detection algorithm for IFU data (as of DMS build B9.3rc1/CAL_VER 1.11.0) implements the basic outlier detection algorithm -- searches for pixels that are consistent outliers in the calibrated images created by the `calwebb_spec2` pipeline. The algorithm generally operates as follows:\n",
    "\n",
    "> * Identifies outlier pixels by comparing them with their neighboring pixels in the spatial direction across a set of input files within an association.\n",
    "> * For NIRSpec data, it calculates differences between pixels located above and below each science pixel.\n",
    "> * The pixel differences for every input model in the association are computed and stored in a stack of pixel differences.\n",
    "> * For each pixel, the algorithm determines the minimum difference across this stack and then performs normalization. This normalization process employs a local median derived from the difference array, with the size of the median determined by the kernel size.\n",
    "> * A pixel is flagged as an outlier if this normalized minimum difference is greater than the input threshold percentage. \n",
    "> * Pixels that are found to be outliers are flaged in in the DQ array.\n",
    "> * [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/outlier_detection_ifu.html#outlier-detection-ifu)\n",
    "\n",
    "\n",
    "**[The outlier_detection step for IFU data has the following optional arguments that control the behavior of the processing](https://github.com/spacetelescope/jwst/blob/master/docs/jwst/outlier_detection/arguments.rst):**\n",
    "\n",
    "* `kernel_size` (string, default='7 7'): The size of the kernel to use to normalize the pixel differences. The kernel size must only contain odd values.\n",
    "* `threshold_percent` (float, default=99.8): The threshold (in percent) of the normalized minimum pixel difference used to identify bad pixels. Pixels with a normalized minimum pixel difference above this percentage are flagged as a outlier.\n",
    "* `save_intermediate_results` (boolean, default=False): Specifies whether or not to save any intermediate products created during step processing.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> The default `kernel_size` of **7 7** was developed for MIRI/MRS and tests showed that **3 3** works the better option for NIRSpec.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a12db-7809-4f0d-8e9d-b8d81131e63c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Rerun stage 3\n",
    "\n",
    "result = Spec3Pipeline.call(asnfile,\n",
    "                            save_results = True,\n",
    "                            output_dir = output_dir,\n",
    "                            steps = {\"outlier_detection\":{\"skip\": False,\n",
    "                                                          \"save_results\": True,\n",
    "                                                          \"kernel_size\": '3 3',    # the default of 7 7 was developed for MIRI/MRS and from testing 3 3 is the better option for NIRSpec\n",
    "                                                          \"threshold_percent\": 99.8\n",
    "                                                         },\n",
    "                                    \"cube_build\":{\"skip\": False,\n",
    "                                                  # \"gratings\": \"ALL\",      ### “ALL” is used, then all the gratings in the association are used.\n",
    "                                                  # \"output_type\": \"multi\", ### combines data into a single “uber” IFU cube \"\n",
    "                                                  \"weighting\": 'emsm'    ### From testing emsm seems to be working better than drizzle for NIRSpec\n",
    "                                                 },\n",
    "                                    \"extract_1d\":{\"skip\": False,\n",
    "                                                  \"subtract_background\": False, ### Do not automatically apply background subtraction until we modify the extraction region\n",
    "                                                  # \"center_xy\": \"27, 28\",  ### A list of two integer values giving the desired x/y location for the center of the circular extraction aperture,\n",
    "                                                  \"ifu_autocen\": True  ### Switch to select whether or not to enable auto-centroiding of the extraction aperture for IFU point sources\n",
    "                                                 }\n",
    "                                    })\n",
    "print(\"Hurray ... this step has been completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Calibrated 3-D data cubes at various wavelentgths\n",
    "\n",
    "s3d_stage3_list = sorted(glob.glob(os.path.join(output_dir, '*nirspec*_s3d.fits')))\n",
    "title_stage3_rerun='NGC 7319 AGN \\n Level 3 IFU Product: 3-D Cube Slices vs. Corresponding 3-D Weighted Map'\n",
    "\n",
    "#Characteristics of the plot \n",
    "nrs1_wavelengths = [1.4,3.3,4.5] #Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_spaxel_locs = [[30,29],[28,39],[14,25]] #Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "vmin_vmax_point = [[0,150],[0,150],[0,150]]\n",
    "\n",
    "#Plot using the convience function defined above\n",
    "show_ifu_cubeslices(s3d_stage3_list, wavelength_slices=[nrs1_wavelengths], spaxel_locs=[nrs1_spaxel_locs],vmin_vmax=[vmin_vmax_point], title=title_stage3_rerun, title_font=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f8a59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> In comparison to the [weight maps for the 3-D data cube products found in MAST](#level3_mast), the implementation of the new outlier detection algorithm leads to a notable decrease in data rejection.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c96634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Extracted 1-D Spectrum \n",
    "\n",
    "#Combined 1-D extracted spectrum\n",
    "x1d3_rerun_point = datamodels.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_x1d.fits'))[0])\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "x1d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_x1d.fits'))[0])\n",
    "\n",
    "### Obtaining the reference file from teh CRDS cache\n",
    "# extract1d_ref_og = glob.glob(os.path.join(os.getenv('CRDS_PATH'),'references', 'jwst', 'nirspec', '*extract1d*.asdf'))[0]\n",
    "extract1d_ref_og = Spec3Pipeline().get_reference_file(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0], 'extract1d')\n",
    "\n",
    "\n",
    "#Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_rerun_point = x1d3_rerun_point.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_rerun_point = x1d3_rerun_point.spec[0].spec_table.FLUX\n",
    "\n",
    "#Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(25,9))\n",
    "gs = grd.GridSpec(1, 8, hspace=0.4,wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0:5])\n",
    "ax2 = fig.add_subplot(gs[0, 5:])\n",
    "\n",
    "ax1.plot(x1d3wave_rerun_point,x1d3flux_rerun_point, linewidth =2)\n",
    "\n",
    "#Where wavelength slice was taken above\n",
    "ax1.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "ax1.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "ax1.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "ax1.set_xlabel('$\\lambda [\\mu$m]', fontsize =20)\n",
    "ax1.set_ylabel('Flux (Jy)', fontsize =20)\n",
    "ax1.set_title(\"NGC 7319 AGN \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize=20)\n",
    "ax1.set_ylim(0, 10**-1.6)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(0,-2))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#Extraction Region Preview\n",
    "#Open Combined 3-D Cube FITS file\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "cube = s3d[1].data #Science data\n",
    "\n",
    "#plot the full IFU cube\n",
    "slice_mean = np.nanmean(cube[400:500, :, :], axis=0) #Mean of the slice looking in the range (nslice2-2):(nslice2+2)\n",
    "slice_norm=ImageNormalize(slice_mean, vmin=0, vmax=150, stretch=AsinhStretch()) #normalize &stretch\n",
    "slice_full = ax2.imshow(slice_mean, norm=slice_norm, origin='lower', cmap='jet') #plot slice\n",
    "\n",
    "#colorbar\n",
    "cb_image = plt.colorbar(slice_full, fraction=0.046, pad=0.04)\n",
    "cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 10)\n",
    "cb_image.ax.tick_params(labelsize=10)\n",
    "cb_image.ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "\n",
    "with asdf.open(extract1d_ref_og, mode='r') as ff:\n",
    "    print(\"===========================================================\")\n",
    "    print(\"          Radius [arcsec]:\", ff.tree['data']['radius'][0])\n",
    "    print(\"Inner background [arcsec]:\", ff.tree['data']['inner_bkg'][0])\n",
    "    print(\"Outer background [arcsec]:\", ff.tree['data']['outer_bkg'][0])\n",
    "    print(\"===========================================================\")\n",
    "    \n",
    "    radius = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['radius'][0] * 10, fill=False, label='Radius')\n",
    "    inner_bkg = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['inner_bkg'][0] * 10, color='b',fill=False, label='Inner Background Radius')\n",
    "    outer_bkg= Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['outer_bkg'][0] * 10, color='r',fill=False, label='Outer Background Radius')\n",
    "\n",
    "\n",
    "ax2.add_patch(radius)\n",
    "ax2.add_patch(inner_bkg)\n",
    "ax2.add_patch(outer_bkg)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.set_xlabel('X (pixels)', fontsize=10)\n",
    "ax2.set_ylabel('Y (pixels)', fontsize=10)\n",
    "ax2.grid(color='white', ls='solid')\n",
    "ax2.set_title('Full IFU Cube: \\n Extraction Region Preview', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599ead0-6eb4-4450-b13c-2f66f377851d",
   "metadata": {},
   "source": [
    "## 8. Extract 1-D Step: Modified Reference File<a id='extract_1d'></a>\n",
    "<hr style=\"border:1px solid gray\">  \n",
    "\n",
    "As a point source, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file:\n",
    "\n",
    ">[Extraction for 3-D IFU Data:](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    ">\n",
    "> For point source data the extraction aperture is centered at the RA/DEC target location indicated by the header. If the target location is undefined in the header, then the extraction region is the center of the IFU cube.\n",
    ">\n",
    ">For point sources a circular extraction aperture is used, along with an optional circular annulus for background extraction and subtraction. The size of the extraction region and the background annulus size varies with wavelength. The extraction related vectors are found in the asdf EXTRACT1D reference file. For each element in the wavelength vector there are three size components: `radius`, `inner_bkg`, and `outer_bkg`. The radius vector sets the extraction size; while `inner_bkg` and `outer_bkg` specify the limits of an annular background aperture. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The `ifu_autocen` parameter provides a new method to center on the point sources even if the header information is not perfect due to inaccruacries caused by, e.g., FGS.\n",
    "Nevertheless, I you woudl like to adjust the extraction position, we show how to modify the EXTRACT1D reference file to obtain better results. \n",
    "\n",
    "</div>\n",
    "\n",
    "To do so we first need to obtain the correct `extract1d` reference file from CRDS and copy it into the run folder and change the the `radius` and `inner_bkg` and `outer_bkg` parameters.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> The default extraction aperture radius has been set to match what was used to derive the flux calibration. If you want to use a different aperture size, you will need to compute and apply a custom aperture correction to ensure the correct flux, as we have not yet updated the aperture correction reference files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87608a-82e3-4cde-95b8-fc0d088a309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the defualt extract1d reference file and copy to working directory\n",
    "extract1d_ref_og = Spec3Pipeline().get_reference_file(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0], 'extract1d')\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir, os.path.basename(extract1d_ref_og))):\n",
    "    shutil.copy(extract1d_ref_og, os.path.join(output_dir, os.path.basename(extract1d_ref_og)))\n",
    "\n",
    "#Make Changes to the ASDF file and Write to a new file\n",
    "\n",
    "with asdf.open(os.path.join(output_dir, os.path.basename(extract1d_ref_og)), mode='rw') as ff:\n",
    "\n",
    "    ff.tree['data']['radius'] = np.full((2048,), 0.9, dtype='float32')\n",
    "    ff.tree['data']['inner_bkg'] = np.full((2048,), 1.0, dtype='float32')\n",
    "    ff.tree['data']['outer_bkg'] = np.full((2048,), 1.5, dtype='float32')\n",
    "    ff.write_to(os.path.join(output_dir, 'new_' + os.path.basename(extract1d_ref_og)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9ad41-8ca6-4b94-a5f5-f800e0840acc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Now we re-extract the 1D spectrum but just running the `Extract1dStep` and overriding the reference file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714203e-4ea9-43df-ae40-dac33fb8cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract1dStep.call(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0], \n",
    "                       save_results = True,\n",
    "                       output_dir = output_dir,\n",
    "                       override_extract1d = os.path.join(output_dir,  'new_' + os.path.basename(extract1d_ref_og)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e491187-78c1-474e-a571-85f948a75a97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Finally we plot the newly extracted 1D spectrum while also showing the originally extracted one.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e7fb9-181f-4b0e-9e65-579eb153fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3 Products -- Combined Extracted 1-D Spectrum \n",
    "\n",
    "#Combined 1-D extracted spectrum\n",
    "x1d3_shifted_extract_point = datamodels.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_extract1dstep.fits'))[0])\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "x1d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_extract1dstep.fits'))[0])\n",
    "\n",
    "#Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_shifted_extract_point = x1d3_shifted_extract_point.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_shifted_extract_point = x1d3_shifted_extract_point.spec[0].spec_table.FLUX\n",
    "\n",
    "#Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(25,9))\n",
    "gs = grd.GridSpec(1, 8, hspace=0.4,wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0:5])\n",
    "ax2 = fig.add_subplot(gs[0, 5:])\n",
    "\n",
    "ax1.plot(x1d3wave_shifted_extract_point,x1d3flux_shifted_extract_point, linewidth =2, label=\"shifted extraction\")\n",
    "ax1.plot(x1d3wave_rerun_point, x1d3flux_rerun_point, linewidth =2, color='grey', label=\"original extraction\")\n",
    "\n",
    "\n",
    "#Where wavelength slice was taken above\n",
    "ax1.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "ax1.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "ax1.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "ax1.set_xlabel('$\\lambda [\\mu$m]', fontsize =20)\n",
    "ax1.set_ylabel('Flux (Jy)', fontsize =20)\n",
    "ax1.set_title(\"NGC 7319 AGN \\n Level 3 IFU Product in MAST: Extracted 1-D Spectrum\", fontsize=20)\n",
    "ax1.set_ylim(0, 10**-1.6)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(0,-2))\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "#Extraction Region Preview\n",
    "#Open Combined 3-D Cube FITS file\n",
    "s3d = fits.open(glob.glob(os.path.join(output_dir, '*nirspec_prism-clear_s3d.fits'))[0])\n",
    "cube = s3d[1].data #Science data\n",
    "\n",
    "#plot the full IFU cube\n",
    "slice_mean = np.nanmean(cube[400:500, :, :], axis=0) #Mean of the slice looking in the range (nslice2-2):(nslice2+2)\n",
    "slice_norm=ImageNormalize(slice_mean, vmin=0, vmax=150, stretch=AsinhStretch()) #normalize &stretch\n",
    "slice_full = ax2.imshow(slice_mean, norm=slice_norm, origin='lower', cmap='jet') #plot slice\n",
    "\n",
    "#colorbar\n",
    "cb_image = plt.colorbar(slice_full, fraction=0.046, pad=0.04)\n",
    "cb_image.set_label('MJy/sr', labelpad=-1, fontsize = 10)\n",
    "cb_image.ax.tick_params(labelsize=10)\n",
    "cb_image.ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "\n",
    "with asdf.open(os.path.join(output_dir, 'new_' + os.path.basename(extract1d_ref_og)), mode='r') as ff:\n",
    "    print(\"          Radius [arcsec]:\", ff.tree['data']['radius'][0])\n",
    "    print(\"Inner background [arcsec]:\", ff.tree['data']['inner_bkg'][0])\n",
    "    print(\"Outer background [arcsec]:\", ff.tree['data']['outer_bkg'][0])\n",
    "    \n",
    "    radius = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['radius'][0] * 10, fill=False, label='Radius')\n",
    "    inner_bkg = Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['inner_bkg'][0] * 10, color='b',fill=False, label='Inner Background Radius')\n",
    "    outer_bkg= Circle((x1d[1].header['EXTR_X'],x1d[1].header['EXTR_Y']),ff.tree['data']['outer_bkg'][0] * 10, color='r',fill=False, label='Outer Background Radius')\n",
    "\n",
    "\n",
    "ax2.add_patch(radius)\n",
    "ax2.add_patch(inner_bkg)\n",
    "ax2.add_patch(outer_bkg)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.set_xlabel('X (pixels)', fontsize=10)\n",
    "ax2.set_ylabel('Y (pixels)', fontsize=10)\n",
    "ax2.grid(color='white', ls='solid')\n",
    "ax2.set_title('Full IFU Cube: \\n Extraction Region Preview', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a83b7-9146-4b06-85ab-748f03bea734",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "In conclusion, this notebook walks users through processing real data (NGC 7319 AGN) from Proposal ID 2732 and comparing automated products in MAST with those generated using the latest version of the JWST calibration pipeline and latest CRDS context. For optimal results, users are strongly encouraged to reprocess their own data using the most recent pipeline version and CRDS context, taking advantage of bug fixes and algorithm improvements (i.e., the new IFU outlier detection algorithm). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (masterclass)",
   "language": "python",
   "name": "masterclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
